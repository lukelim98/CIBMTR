{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc523a40-8015-4ead-8996-926c75efe114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "505cf9ac-d44f-4583-bcfc-ac445fc67c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Data/train.csv')\n",
    "test_data = pd.read_csv('Data/test.csv')\n",
    "data_dict = pd.read_csv('Data/data_dictionary.csv')\n",
    "sample_submission = pd.read_csv('Data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330eb940-54d8-4f29-a77f-2b0948f2004d",
   "metadata": {},
   "source": [
    "# Handling NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f600c3a-e336-4be6-a3c0-c3417663df08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>dri_score</th>\n",
       "      <th>psych_disturb</th>\n",
       "      <th>cyto_score</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hla_match_c_high</th>\n",
       "      <th>hla_high_res_8</th>\n",
       "      <th>tbi_status</th>\n",
       "      <th>arrhythmia</th>\n",
       "      <th>hla_low_res_6</th>\n",
       "      <th>...</th>\n",
       "      <th>tce_div_match</th>\n",
       "      <th>donor_related</th>\n",
       "      <th>melphalan_dose</th>\n",
       "      <th>hla_low_res_8</th>\n",
       "      <th>cardiac</th>\n",
       "      <th>hla_match_drb1_high</th>\n",
       "      <th>pulm_moderate</th>\n",
       "      <th>hla_low_res_10</th>\n",
       "      <th>efs</th>\n",
       "      <th>efs_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>N/A - non-malignant indication</td>\n",
       "      <td>No</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Unrelated</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>TBI +- Other, &gt;cGy</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Related</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>N/A - non-malignant indication</td>\n",
       "      <td>No</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Related</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Unrelated</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Related</td>\n",
       "      <td>MEL</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                       dri_score psych_disturb    cyto_score diabetes  \\\n",
       "0  0.0  N/A - non-malignant indication            No          Poor       No   \n",
       "1  1.0                    Intermediate            No  Intermediate       No   \n",
       "2  2.0  N/A - non-malignant indication            No          Poor       No   \n",
       "3  3.0                            High            No  Intermediate       No   \n",
       "4  4.0                            High            No  Intermediate       No   \n",
       "\n",
       "   hla_match_c_high  hla_high_res_8          tbi_status arrhythmia  \\\n",
       "0               2.0             7.0              No TBI         No   \n",
       "1               2.0             8.0  TBI +- Other, >cGy         No   \n",
       "2               2.0             8.0              No TBI         No   \n",
       "3               2.0             8.0              No TBI         No   \n",
       "4               2.0             8.0              No TBI         No   \n",
       "\n",
       "   hla_low_res_6  ...          tce_div_match donor_related  \\\n",
       "0            6.0  ...  Permissive mismatched     Unrelated   \n",
       "1            6.0  ...  Permissive mismatched       Related   \n",
       "2            6.0  ...  Permissive mismatched       Related   \n",
       "3            6.0  ...  Permissive mismatched     Unrelated   \n",
       "4            6.0  ...  Permissive mismatched       Related   \n",
       "\n",
       "       melphalan_dose hla_low_res_8 cardiac  hla_match_drb1_high  \\\n",
       "0  N/A, Mel not given           8.0      No                  2.0   \n",
       "1  N/A, Mel not given           8.0      No                  2.0   \n",
       "2  N/A, Mel not given           8.0      No                  2.0   \n",
       "3  N/A, Mel not given           8.0      No                  2.0   \n",
       "4                 MEL           8.0      No                  2.0   \n",
       "\n",
       "  pulm_moderate  hla_low_res_10  efs efs_time  \n",
       "0            No            10.0  0.0   42.356  \n",
       "1           Yes            10.0  1.0    4.672  \n",
       "2            No            10.0  0.0   19.793  \n",
       "3            No            10.0  0.0  102.349  \n",
       "4            No            10.0  0.0   16.223  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "\n",
    "def handle_missing_values(data):\n",
    "    # Separating categorical and numeric columns\n",
    "    cat_cols = [col for col in data.columns if data[col].dtype == 'object']\n",
    "    num_cols = [col for col in data.columns if col not in cat_cols]\n",
    "\n",
    "    # Handling missing numerical data with KNNImputer\n",
    "    knn_imputer = KNNImputer(n_neighbors=5)\n",
    "    data[num_cols] = knn_imputer.fit_transform(data[num_cols])\n",
    "\n",
    "    # Imputing categorical data with KNeighborsClassifier\n",
    "    for col in cat_cols:\n",
    "        missing_mask = data[col].isna()\n",
    "        if missing_mask.sum() > 0:\n",
    "            # Separate training and rpediction sets\n",
    "            X_train = data.loc[~missing_mask, num_cols]\n",
    "            y_train = data.loc[~missing_mask, col]\n",
    "            X_missing = data.loc[missing_mask, num_cols]\n",
    "\n",
    "            # Train a KNeighborsClassifier\n",
    "            knn = KNeighborsClassifier(n_neighbors=5)\n",
    "            knn.fit(X_train, y_train)\n",
    "            imputed_values = knn.predict(X_missing)\n",
    "\n",
    "            # Fill missing values\n",
    "            data.loc[missing_mask, col] = imputed_values\n",
    "\n",
    "    return data\n",
    "\n",
    "train_data = handle_missing_values(train_data)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0035096-56aa-49f6-b1aa-6fa1514c4368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dri_score\n",
      "Intermediate                                         10505\n",
      "N/A - pediatric                                       4808\n",
      "High                                                  4737\n",
      "N/A - non-malignant indication                        2435\n",
      "TBD cytogenetics                                      2007\n",
      "Low                                                   1929\n",
      "High - TED AML case <missing cytogenetics             1417\n",
      "Intermediate - TED AML case <missing cytogenetics      483\n",
      "N/A - disease not classifiable                         272\n",
      "Very high                                              198\n",
      "Missing disease status                                   9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "psych_disturb\n",
      "No          25017\n",
      "Yes          3637\n",
      "Not done      146\n",
      "Name: count, dtype: int64\n",
      "\n",
      "cyto_score\n",
      "Poor            12878\n",
      "Intermediate     9179\n",
      "Favorable        3910\n",
      "TBD              1511\n",
      "Normal            716\n",
      "Other             551\n",
      "Not tested         55\n",
      "Name: count, dtype: int64\n",
      "\n",
      "diabetes\n",
      "No          24212\n",
      "Yes          4447\n",
      "Not done      141\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hla_match_c_high\n",
      "2.0    19736\n",
      "1.0     5545\n",
      "1.8     1785\n",
      "1.6     1181\n",
      "1.4      403\n",
      "0.0       79\n",
      "1.2       71\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hla_high_res_8\n",
      "8.0    13964\n",
      "4.0     3820\n",
      "7.0     2995\n",
      "6.0     1776\n",
      "5.0     1690\n",
      "7.2      784\n",
      "6.4      591\n",
      "6.6      539\n",
      "6.8      504\n",
      "6.2      420\n",
      "7.4      412\n",
      "7.6      348\n",
      "7.8      327\n",
      "5.8      233\n",
      "5.6      198\n",
      "5.4       72\n",
      "5.2       58\n",
      "3.0       28\n",
      "4.8       26\n",
      "4.6        5\n",
      "4.2        4\n",
      "4.4        4\n",
      "2.0        2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "tbi_status\n",
      "No TBI                              18861\n",
      "TBI + Cy +- Other                    6104\n",
      "TBI +- Other, <=cGy                  1727\n",
      "TBI +- Other, >cGy                   1700\n",
      "TBI +- Other, -cGy, single            134\n",
      "TBI +- Other, -cGy, fractionated      119\n",
      "TBI +- Other, -cGy, unknown dose       79\n",
      "TBI +- Other, unknown dose             76\n",
      "Name: count, dtype: int64\n",
      "\n",
      "arrhythmia\n",
      "No          27401\n",
      "Yes          1281\n",
      "Not done      118\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hla_low_res_6\n",
      "6.0    15949\n",
      "3.0     4957\n",
      "5.0     3177\n",
      "4.0     2108\n",
      "5.4      610\n",
      "4.8      489\n",
      "5.2      357\n",
      "5.6      250\n",
      "4.6      243\n",
      "5.8      221\n",
      "4.4      170\n",
      "4.2      170\n",
      "3.6       38\n",
      "3.8       32\n",
      "2.0       22\n",
      "3.4        6\n",
      "3.2        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "graft_type\n",
      "Peripheral blood    20546\n",
      "Bone marrow          8254\n",
      "Name: count, dtype: int64\n",
      "\n",
      "vent_hist\n",
      "No     27980\n",
      "Yes      820\n",
      "Name: count, dtype: int64\n",
      "\n",
      "renal_issue\n",
      "No          28463\n",
      "Yes           200\n",
      "Not done      137\n",
      "Name: count, dtype: int64\n",
      "\n",
      "pulm_severe\n",
      "No          26906\n",
      "Yes          1714\n",
      "Not done      180\n",
      "Name: count, dtype: int64\n",
      "\n",
      "prim_disease_hct\n",
      "ALL                     8102\n",
      "AML                     7135\n",
      "MDS                     3046\n",
      "IPA                     1719\n",
      "MPN                     1656\n",
      "IEA                     1449\n",
      "NHL                     1319\n",
      "IIS                     1024\n",
      "PCD                      869\n",
      "SAA                      713\n",
      "AI                       449\n",
      "HIS                      445\n",
      "Other leukemia           366\n",
      "Solid tumor              207\n",
      "IMD                      144\n",
      "Other acute leukemia      83\n",
      "HD                        54\n",
      "CML                       20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hla_high_res_6\n",
      "6.0    14393\n",
      "3.0     4599\n",
      "5.0     3337\n",
      "4.0     2239\n",
      "5.4      857\n",
      "4.8      714\n",
      "5.2      679\n",
      "4.6      464\n",
      "5.6      416\n",
      "5.8      351\n",
      "4.4      320\n",
      "4.2      264\n",
      "3.8       73\n",
      "2.0       43\n",
      "3.6       35\n",
      "3.2        8\n",
      "3.4        7\n",
      "0.0        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "cmv_status\n",
      "+/+    14073\n",
      "-/+     7170\n",
      "+/-     4092\n",
      "-/-     3465\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hla_high_res_10\n",
      "10.0    12630\n",
      "5.0      3161\n",
      "9.0      3152\n",
      "8.0      1910\n",
      "6.0      1380\n",
      "7.0      1349\n",
      "8.8       651\n",
      "8.6       554\n",
      "8.2       518\n",
      "8.4       507\n",
      "9.2       440\n",
      "7.8       431\n",
      "9.4       395\n",
      "9.6       380\n",
      "9.8       340\n",
      "7.6       293\n",
      "7.4       218\n",
      "7.2       198\n",
      "6.8       106\n",
      "6.6        67\n",
      "6.4        44\n",
      "6.2        33\n",
      "4.0        25\n",
      "5.8         9\n",
      "5.4         4\n",
      "5.6         3\n",
      "5.2         1\n",
      "3.0         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hla_match_dqb1_high\n",
      "2.0    18537\n",
      "1.0     6074\n",
      "1.8     1935\n",
      "1.6     1474\n",
      "1.4      582\n",
      "1.2      121\n",
      "0.0       77\n",
      "Name: count, dtype: int64\n",
      "\n",
      "tce_imm_match\n",
      "P/P    23230\n",
      "G/G     3289\n",
      "H/H     1265\n",
      "G/B      609\n",
      "H/B      233\n",
      "P/H       83\n",
      "P/B       66\n",
      "P/G       25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hla_nmdp_6\n",
      "6.0    15470\n",
      "3.0     4893\n",
      "5.0     3700\n",
      "4.0     1350\n",
      "5.4      769\n",
      "4.8      581\n",
      "5.2      580\n",
      "5.8      353\n",
      "4.6      322\n",
      "5.6      292\n",
      "4.2      192\n",
      "4.4      183\n",
      "3.8       37\n",
      "2.0       35\n",
      "3.6       34\n",
      "3.4        9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hla_match_c_low\n",
      "2.0    20404\n",
      "1.0     6145\n",
      "1.8     1092\n",
      "1.6      730\n",
      "1.4      280\n",
      "0.0       79\n",
      "1.2       70\n",
      "Name: count, dtype: int64\n",
      "\n",
      "rituximab\n",
      "No     28181\n",
      "Yes      619\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hla_match_drb1_low\n",
      "2.0    19154\n",
      "1.0     7452\n",
      "1.8      975\n",
      "1.6      807\n",
      "1.4      338\n",
      "1.2       74\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hla_match_dqb1_low\n",
      "2.0    20242\n",
      "1.0     5389\n",
      "1.8     1632\n",
      "1.6     1030\n",
      "1.4      346\n",
      "0.0       91\n",
      "1.2       70\n",
      "Name: count, dtype: int64\n",
      "\n",
      "prod_type\n",
      "PB    20381\n",
      "BM     8419\n",
      "Name: count, dtype: int64\n",
      "\n",
      "cyto_score_detail\n",
      "Intermediate    21814\n",
      "Poor             4002\n",
      "Favorable        1699\n",
      "TBD              1139\n",
      "Not tested        146\n",
      "Name: count, dtype: int64\n",
      "\n",
      "conditioning_intensity\n",
      "MAC                              16634\n",
      "RIC                               8039\n",
      "NMA                               3604\n",
      "TBD                                374\n",
      "No drugs reported                   87\n",
      "N/A, F(pre-TED) not submitted       62\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ethnicity\n",
      "Not Hispanic or Latino      25061\n",
      "Hispanic or Latino           3355\n",
      "Non-resident of the U.S.      384\n",
      "Name: count, dtype: int64\n",
      "\n",
      "year_hct\n",
      "2018.0    7336\n",
      "2016.0    5049\n",
      "2017.0    4830\n",
      "2008.0    2544\n",
      "2015.0    2243\n",
      "2013.0    1871\n",
      "2012.0    1571\n",
      "2014.0    1098\n",
      "2019.0     774\n",
      "2011.0     599\n",
      "2009.0     503\n",
      "2010.0     378\n",
      "2020.0       4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "obesity\n",
      "No          26900\n",
      "Yes          1783\n",
      "Not done      117\n",
      "Name: count, dtype: int64\n",
      "\n",
      "mrd_hct\n",
      "Negative    21120\n",
      "Positive     7680\n",
      "Name: count, dtype: int64\n",
      "\n",
      "in_vivo_tcd\n",
      "No     17746\n",
      "Yes    11054\n",
      "Name: count, dtype: int64\n",
      "\n",
      "tce_match\n",
      "Permissive            21125\n",
      "GvH non-permissive     3827\n",
      "Fully matched          2179\n",
      "HvG non-permissive     1669\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hla_match_a_high\n",
      "2.0    18031\n",
      "1.0     7147\n",
      "1.8     1489\n",
      "1.6     1340\n",
      "1.4      591\n",
      "1.2      139\n",
      "0.0       63\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hepatic_severe\n",
      "No          27106\n",
      "Yes          1484\n",
      "Not done      210\n",
      "Name: count, dtype: int64\n",
      "\n",
      "donor_age\n",
      "23.570    7\n",
      "24.504    6\n",
      "25.378    6\n",
      "26.541    5\n",
      "25.717    5\n",
      "         ..\n",
      "50.209    1\n",
      "43.231    1\n",
      "33.051    1\n",
      "54.578    1\n",
      "30.571    1\n",
      "Name: count, Length: 22617, dtype: int64\n",
      "\n",
      "prior_tumor\n",
      "No          25467\n",
      "Yes          3048\n",
      "Not done      285\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hla_match_b_low\n",
      "2.0    19384\n",
      "1.0     7227\n",
      "1.8      921\n",
      "1.6      774\n",
      "1.4      353\n",
      "1.2       77\n",
      "0.0       64\n",
      "Name: count, dtype: int64\n",
      "\n",
      "peptic_ulcer\n",
      "No          28375\n",
      "Yes           259\n",
      "Not done      166\n",
      "Name: count, dtype: int64\n",
      "\n",
      "age_at_hct\n",
      "0.044     1005\n",
      "64.470       6\n",
      "15.820       6\n",
      "63.701       5\n",
      "65.184       5\n",
      "          ... \n",
      "52.191       1\n",
      "34.487       1\n",
      "42.467       1\n",
      "21.377       1\n",
      "13.988       1\n",
      "Name: count, Length: 22168, dtype: int64\n",
      "\n",
      "hla_match_a_low\n",
      "2.0    19163\n",
      "1.0     7595\n",
      "1.8      870\n",
      "1.6      701\n",
      "1.4      345\n",
      "1.2       77\n",
      "0.0       49\n",
      "Name: count, dtype: int64\n",
      "\n",
      "gvhd_proph\n",
      "FK+ MMF +- others                  10546\n",
      "Cyclophosphamide alone              5311\n",
      "FK+ MTX +- others(not MMF)          4280\n",
      "Cyclophosphamide +- others          2387\n",
      "CSA + MMF +- others(not FK)         2305\n",
      "FKalone                             1237\n",
      "Other GVHD Prophylaxis               550\n",
      "TDEPLETION alone                     545\n",
      "TDEPLETION +- other                  540\n",
      "No GvHD Prophylaxis                  262\n",
      "CDselect alone                       255\n",
      "CSA + MTX +- others(not MMF,FK)      225\n",
      "CSA alone                            215\n",
      "Parent Q = yes, but no agent          62\n",
      "CDselect +- other                     56\n",
      "CSA +- others(not FK,MMF,MTX)         23\n",
      "FK+- others(not MMF,MTX)               1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "rheum_issue\n",
      "No          28198\n",
      "Yes           457\n",
      "Not done      145\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sex_match\n",
      "M-M    8031\n",
      "F-M    7906\n",
      "M-F    6757\n",
      "F-F    6106\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hla_match_b_high\n",
      "2.0    17995\n",
      "1.0     7288\n",
      "1.8     1382\n",
      "1.6     1317\n",
      "1.4      617\n",
      "1.2      123\n",
      "0.0       77\n",
      "0.8        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "race_group\n",
      "More than one race                           4845\n",
      "Asian                                        4832\n",
      "White                                        4831\n",
      "Black or African-American                    4795\n",
      "American Indian or Alaska Native             4790\n",
      "Native Hawaiian or other Pacific Islander    4707\n",
      "Name: count, dtype: int64\n",
      "\n",
      "comorbidity_score\n",
      "0.0     10744\n",
      "2.0      5938\n",
      "1.0      4881\n",
      "3.0      2479\n",
      "4.0      1400\n",
      "5.0      1220\n",
      "6.0       708\n",
      "7.0       492\n",
      "8.0       293\n",
      "9.0       190\n",
      "10.0       76\n",
      "1.2        45\n",
      "0.8        40\n",
      "1.4        37\n",
      "1.8        35\n",
      "0.6        33\n",
      "2.4        29\n",
      "1.6        27\n",
      "2.6        25\n",
      "2.2        18\n",
      "2.8        17\n",
      "0.4        13\n",
      "3.6        12\n",
      "3.4        11\n",
      "0.2        11\n",
      "3.2         8\n",
      "4.4         6\n",
      "3.8         5\n",
      "4.6         3\n",
      "4.2         2\n",
      "5.6         1\n",
      "5.2         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "karnofsky_score\n",
      "90.0     15416\n",
      "70.0      6698\n",
      "100.0     2476\n",
      "80.0      2119\n",
      "60.0      1291\n",
      "86.0       132\n",
      "82.0       127\n",
      "88.0       113\n",
      "84.0        99\n",
      "50.0        91\n",
      "78.0        69\n",
      "92.0        52\n",
      "76.0        44\n",
      "94.0        24\n",
      "74.0        19\n",
      "72.0        14\n",
      "40.0        10\n",
      "68.0         3\n",
      "96.0         3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hepatic_mild\n",
      "No          26895\n",
      "Yes          1765\n",
      "Not done      140\n",
      "Name: count, dtype: int64\n",
      "\n",
      "tce_div_match\n",
      "Permissive mismatched            23181\n",
      "GvH non-permissive                3229\n",
      "HvG non-permissive                1733\n",
      "Bi-directional non-permissive      657\n",
      "Name: count, dtype: int64\n",
      "\n",
      "donor_related\n",
      "Related                     16302\n",
      "Unrelated                   12152\n",
      "Multiple donor (non-UCB)      346\n",
      "Name: count, dtype: int64\n",
      "\n",
      "melphalan_dose\n",
      "N/A, Mel not given    21370\n",
      "MEL                    7430\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hla_low_res_8\n",
      "8.0    15430\n",
      "4.0     4260\n",
      "7.0     2976\n",
      "6.0     1664\n",
      "5.0     1636\n",
      "7.2      564\n",
      "6.4      410\n",
      "6.6      316\n",
      "6.8      296\n",
      "7.4      247\n",
      "7.8      220\n",
      "6.2      209\n",
      "7.6      178\n",
      "5.6      145\n",
      "5.8      118\n",
      "5.4       43\n",
      "4.8       30\n",
      "5.2       25\n",
      "3.0       23\n",
      "4.6        4\n",
      "4.4        3\n",
      "4.2        2\n",
      "2.0        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "cardiac\n",
      "No          27126\n",
      "Yes          1527\n",
      "Not done      147\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hla_match_drb1_high\n",
      "2.0    18608\n",
      "1.0     7323\n",
      "1.8     1177\n",
      "1.6     1055\n",
      "1.4      450\n",
      "1.2      115\n",
      "0.0       71\n",
      "0.8        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "pulm_moderate\n",
      "No          23251\n",
      "Yes          5383\n",
      "Not done      166\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hla_low_res_10\n",
      "10.0    14054\n",
      "5.0      3211\n",
      "9.0      3169\n",
      "8.0      1790\n",
      "6.0      1676\n",
      "7.0      1299\n",
      "8.8       467\n",
      "8.2       405\n",
      "8.4       377\n",
      "8.6       371\n",
      "9.2       321\n",
      "9.4       265\n",
      "9.6       264\n",
      "7.8       256\n",
      "9.8       254\n",
      "7.6       159\n",
      "7.4       139\n",
      "7.2       135\n",
      "6.8        47\n",
      "6.4        43\n",
      "6.6        38\n",
      "4.0        26\n",
      "6.2        21\n",
      "5.8         8\n",
      "5.6         2\n",
      "5.4         2\n",
      "5.2         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "efs\n",
      "1.0    15532\n",
      "0.0    13268\n",
      "Name: count, dtype: int64\n",
      "\n",
      "efs_time\n",
      "5.697     10\n",
      "5.643     10\n",
      "5.801      9\n",
      "5.608      9\n",
      "5.886      9\n",
      "          ..\n",
      "4.430      1\n",
      "19.391     1\n",
      "23.336     1\n",
      "36.169     1\n",
      "25.158     1\n",
      "Name: count, Length: 19208, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in train_data.columns:\n",
    "    if column == 'ID':\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"{train_data[column].value_counts(dropna=False)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb53efe-dee5-44c4-b774-d0371b13051f",
   "metadata": {},
   "source": [
    "# Simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d0f16a3-6d69-4f74-be6c-0efe7b949fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target and drop unneeded columns\n",
    "y = train_data['efs']\n",
    "X = train_data.drop(columns=['efs', 'efs_time', 'ID'], errors='ignore')\n",
    "\n",
    "# Encode categorical variables\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == 'object']\n",
    "X = pd.get_dummies(X, columns=cat_cols, dummy_na=False)\n",
    "\n",
    "# Scale numeric featuers\n",
    "num_cols = [col for col in X.columns if col not in cat_cols]\n",
    "scaler = StandardScaler()\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "\n",
    "# Ensure all numerica\n",
    "X = X.astype(np.float32)\n",
    "\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_array = X.values.astype(np.float32)\n",
    "y_array = y.values.astype(np.float32)\n",
    "\n",
    "# Split into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_array, y_array, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "# Create Datasets and Dataloaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2329944-db15-40c7-8e10-c23f5aa2e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "\n",
    "# Define a simple feedforward model\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5574658c-4a03-4f42-be1e-d5189f729daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.6054, Val Loss: 0.5911, Val Acc: 0.6826\n",
      "Epoch 2/100, Train Loss: 0.5848, Val Loss: 0.5944, Val Acc: 0.6813\n",
      "Epoch 3/100, Train Loss: 0.5768, Val Loss: 0.5926, Val Acc: 0.6868\n",
      "Epoch 4/100, Train Loss: 0.5690, Val Loss: 0.5961, Val Acc: 0.6786\n",
      "Epoch 5/100, Train Loss: 0.5583, Val Loss: 0.6019, Val Acc: 0.6786\n",
      "Epoch 6/100, Train Loss: 0.5446, Val Loss: 0.6137, Val Acc: 0.6760\n",
      "Epoch 7/100, Train Loss: 0.5318, Val Loss: 0.6224, Val Acc: 0.6641\n",
      "Epoch 8/100, Train Loss: 0.5168, Val Loss: 0.6337, Val Acc: 0.6608\n",
      "Epoch 9/100, Train Loss: 0.5008, Val Loss: 0.6441, Val Acc: 0.6663\n",
      "Epoch 10/100, Train Loss: 0.4860, Val Loss: 0.6697, Val Acc: 0.6615\n",
      "Epoch 11/100, Train Loss: 0.4419, Val Loss: 0.6734, Val Acc: 0.6602\n",
      "Epoch 12/100, Train Loss: 0.4322, Val Loss: 0.6808, Val Acc: 0.6589\n",
      "Epoch 13/100, Train Loss: 0.4267, Val Loss: 0.6883, Val Acc: 0.6582\n",
      "Epoch 14/100, Train Loss: 0.4223, Val Loss: 0.6925, Val Acc: 0.6528\n",
      "Epoch 15/100, Train Loss: 0.4185, Val Loss: 0.6985, Val Acc: 0.6549\n",
      "Epoch 16/100, Train Loss: 0.4150, Val Loss: 0.7061, Val Acc: 0.6523\n",
      "Epoch 17/100, Train Loss: 0.4118, Val Loss: 0.7111, Val Acc: 0.6530\n",
      "Epoch 18/100, Train Loss: 0.4087, Val Loss: 0.7170, Val Acc: 0.6505\n",
      "Epoch 19/100, Train Loss: 0.4059, Val Loss: 0.7223, Val Acc: 0.6512\n",
      "Epoch 20/100, Train Loss: 0.4032, Val Loss: 0.7287, Val Acc: 0.6509\n",
      "Epoch 21/100, Train Loss: 0.3959, Val Loss: 0.7299, Val Acc: 0.6516\n",
      "Epoch 22/100, Train Loss: 0.3955, Val Loss: 0.7304, Val Acc: 0.6514\n",
      "Epoch 23/100, Train Loss: 0.3952, Val Loss: 0.7312, Val Acc: 0.6517\n",
      "Epoch 24/100, Train Loss: 0.3949, Val Loss: 0.7318, Val Acc: 0.6509\n",
      "Epoch 25/100, Train Loss: 0.3946, Val Loss: 0.7326, Val Acc: 0.6521\n",
      "Epoch 26/100, Train Loss: 0.3943, Val Loss: 0.7332, Val Acc: 0.6521\n",
      "Epoch 27/100, Train Loss: 0.3940, Val Loss: 0.7338, Val Acc: 0.6514\n",
      "Epoch 28/100, Train Loss: 0.3937, Val Loss: 0.7347, Val Acc: 0.6509\n",
      "Epoch 29/100, Train Loss: 0.3934, Val Loss: 0.7353, Val Acc: 0.6521\n",
      "Epoch 30/100, Train Loss: 0.3931, Val Loss: 0.7359, Val Acc: 0.6517\n",
      "Epoch 31/100, Train Loss: 0.3923, Val Loss: 0.7360, Val Acc: 0.6516\n",
      "Epoch 32/100, Train Loss: 0.3923, Val Loss: 0.7360, Val Acc: 0.6516\n",
      "Epoch 33/100, Train Loss: 0.3922, Val Loss: 0.7361, Val Acc: 0.6514\n",
      "Epoch 34/100, Train Loss: 0.3922, Val Loss: 0.7362, Val Acc: 0.6514\n",
      "Epoch 35/100, Train Loss: 0.3922, Val Loss: 0.7362, Val Acc: 0.6512\n",
      "Epoch 36/100, Train Loss: 0.3921, Val Loss: 0.7363, Val Acc: 0.6509\n",
      "Epoch 37/100, Train Loss: 0.3921, Val Loss: 0.7364, Val Acc: 0.6507\n",
      "Epoch 38/100, Train Loss: 0.3921, Val Loss: 0.7364, Val Acc: 0.6507\n",
      "Epoch 39/100, Train Loss: 0.3921, Val Loss: 0.7365, Val Acc: 0.6507\n",
      "Epoch 40/100, Train Loss: 0.3920, Val Loss: 0.7366, Val Acc: 0.6509\n",
      "Epoch 41/100, Train Loss: 0.3920, Val Loss: 0.7366, Val Acc: 0.6509\n",
      "Epoch 42/100, Train Loss: 0.3919, Val Loss: 0.7366, Val Acc: 0.6509\n",
      "Epoch 43/100, Train Loss: 0.3919, Val Loss: 0.7366, Val Acc: 0.6509\n",
      "Epoch 44/100, Train Loss: 0.3919, Val Loss: 0.7366, Val Acc: 0.6509\n",
      "Epoch 45/100, Train Loss: 0.3919, Val Loss: 0.7366, Val Acc: 0.6509\n",
      "Epoch 46/100, Train Loss: 0.3919, Val Loss: 0.7366, Val Acc: 0.6509\n",
      "Epoch 47/100, Train Loss: 0.3919, Val Loss: 0.7366, Val Acc: 0.6509\n",
      "Epoch 48/100, Train Loss: 0.3919, Val Loss: 0.7366, Val Acc: 0.6507\n",
      "Epoch 49/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 50/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 51/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 52/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 53/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 54/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 55/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 56/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 57/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 58/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 59/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 60/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 61/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 62/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 63/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 64/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 65/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 66/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 67/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 68/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 69/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 70/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 71/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 72/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 73/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 74/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 75/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 76/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 77/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 78/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 79/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 80/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 81/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 82/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 83/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 84/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 85/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 86/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 87/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 88/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 89/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 90/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 91/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 92/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 93/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 94/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 95/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 96/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 97/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 98/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 99/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n",
      "Epoch 100/100, Train Loss: 0.3919, Val Loss: 0.7367, Val Acc: 0.6507\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss, and optimizer\n",
    "model = SimpleNet(input_dim=X_train.shape[1])\n",
    "criterion = nn.BCELoss() # Binary cross-entropy loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning Rate scheduler\n",
    "# StepLR\n",
    "# Decrease the learning rate every 10 epochs by a factor of 0.1\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# ReduceLROnPlateaus\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "\n",
    "# Training loop \n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.view(-1) # Flatten for loss calculation\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            outputs = model(inputs).view(-1)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            preds = (outputs >= 0.5).float()\n",
    "            val_correct += (preds == targets).sum().item()\n",
    "            val_total += targets.size(0)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_accuracy = val_correct / val_total\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Update the learning rate using scheduler\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "993e4a4a-2a8f-4b9a-a51f-ce421313e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ImprovedNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32,1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.relu(self.bn1(self.fc1(x))))\n",
    "        x = self.dropout(self.relu(self.bn2(self.fc2(x))))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "def training(model, criterion, optimizer, epochs, train_loader, val_loader, device):\n",
    "    \"\"\"\n",
    "    Train and evaluate the model.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model to train.\n",
    "        train_loader = DataLoader for the training dataset.\n",
    "        val_loader = DataLoader for the validation dataset.\n",
    "        criterion: Loss function.\n",
    "        optimizer: Optimizer for training the model.\n",
    "        scheduler: Learning rate scheduler (optional).\n",
    "        epochs: Number of epochs to train.\n",
    "        device: Device to use for training ('cpu' or 'mps')\n",
    "\n",
    "    Returns:\n",
    "        history: Dictionary containing training and validation metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Move model to the specified device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Learning Rate Scheduler\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_accuracy': [],\n",
    "        'val_auc': []\n",
    "    }\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).view(-1)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        all_targets = []\n",
    "        all_outputs = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                outputs = model(inputs).view(-1)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Collect outputs for metrics\n",
    "                preds = (outputs >= 0.5).float()\n",
    "                val_correct += (preds == targets).sum().item()\n",
    "                val_total += targets.size(0)\n",
    "\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "                all_outputs.extend(outputs.cpu().numpy())\n",
    "\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_val_accuracy = val_correct / val_total\n",
    "        epoch_val_auc = roc_auc_score(all_targets, all_outputs)\n",
    "\n",
    "        # Log metrics\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['val_accuracy'].append(epoch_val_accuracy)\n",
    "        history['val_auc'].append(epoch_val_auc)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{epochs}, \"\n",
    "            f\"Train Loss: {epoch_loss:.4f}, \"\n",
    "            f\"Val Loss: {epoch_val_loss:.4f}, \"\n",
    "            f\"Val Acc: {epoch_val_accuracy:.4f}, \"\n",
    "            f\"Val AUC: {epoch_val_auc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Update the learning rate using scheduler\n",
    "        scheduler.step()\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0e6b54a-5d2f-4902-9dab-4f104dd71337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.6163, Val Loss: 0.5936, Val Acc: 0.6828, Val AUC: 0.7457\n",
      "Epoch 2/100, Train Loss: 0.5976, Val Loss: 0.5925, Val Acc: 0.6802, Val AUC: 0.7481\n",
      "Epoch 3/100, Train Loss: 0.5912, Val Loss: 0.5950, Val Acc: 0.6804, Val AUC: 0.7436\n",
      "Epoch 4/100, Train Loss: 0.5898, Val Loss: 0.5917, Val Acc: 0.6833, Val AUC: 0.7479\n",
      "Epoch 5/100, Train Loss: 0.5853, Val Loss: 0.5930, Val Acc: 0.6835, Val AUC: 0.7461\n",
      "Epoch 6/100, Train Loss: 0.5818, Val Loss: 0.5923, Val Acc: 0.6799, Val AUC: 0.7472\n",
      "Epoch 7/100, Train Loss: 0.5777, Val Loss: 0.5952, Val Acc: 0.6786, Val AUC: 0.7451\n",
      "Epoch 8/100, Train Loss: 0.5759, Val Loss: 0.5994, Val Acc: 0.6792, Val AUC: 0.7438\n",
      "Epoch 9/100, Train Loss: 0.5690, Val Loss: 0.5951, Val Acc: 0.6823, Val AUC: 0.7445\n",
      "Epoch 10/100, Train Loss: 0.5645, Val Loss: 0.5989, Val Acc: 0.6774, Val AUC: 0.7413\n",
      "Epoch 11/100, Train Loss: 0.5522, Val Loss: 0.5984, Val Acc: 0.6778, Val AUC: 0.7422\n",
      "Epoch 12/100, Train Loss: 0.5487, Val Loss: 0.6000, Val Acc: 0.6780, Val AUC: 0.7424\n",
      "Epoch 13/100, Train Loss: 0.5467, Val Loss: 0.6004, Val Acc: 0.6778, Val AUC: 0.7415\n",
      "Epoch 14/100, Train Loss: 0.5415, Val Loss: 0.6016, Val Acc: 0.6776, Val AUC: 0.7415\n",
      "Epoch 15/100, Train Loss: 0.5417, Val Loss: 0.6041, Val Acc: 0.6778, Val AUC: 0.7407\n",
      "Epoch 16/100, Train Loss: 0.5402, Val Loss: 0.6027, Val Acc: 0.6806, Val AUC: 0.7406\n",
      "Epoch 17/100, Train Loss: 0.5379, Val Loss: 0.6052, Val Acc: 0.6762, Val AUC: 0.7400\n",
      "Epoch 18/100, Train Loss: 0.5355, Val Loss: 0.6051, Val Acc: 0.6774, Val AUC: 0.7384\n",
      "Epoch 19/100, Train Loss: 0.5351, Val Loss: 0.6079, Val Acc: 0.6774, Val AUC: 0.7380\n",
      "Epoch 20/100, Train Loss: 0.5358, Val Loss: 0.6103, Val Acc: 0.6780, Val AUC: 0.7372\n",
      "Epoch 21/100, Train Loss: 0.5336, Val Loss: 0.6078, Val Acc: 0.6773, Val AUC: 0.7372\n",
      "Epoch 22/100, Train Loss: 0.5346, Val Loss: 0.6071, Val Acc: 0.6778, Val AUC: 0.7373\n",
      "Epoch 23/100, Train Loss: 0.5306, Val Loss: 0.6093, Val Acc: 0.6738, Val AUC: 0.7368\n",
      "Epoch 24/100, Train Loss: 0.5308, Val Loss: 0.6114, Val Acc: 0.6731, Val AUC: 0.7373\n",
      "Epoch 25/100, Train Loss: 0.5341, Val Loss: 0.6101, Val Acc: 0.6738, Val AUC: 0.7368\n",
      "Epoch 26/100, Train Loss: 0.5306, Val Loss: 0.6104, Val Acc: 0.6783, Val AUC: 0.7376\n",
      "Epoch 27/100, Train Loss: 0.5324, Val Loss: 0.6102, Val Acc: 0.6760, Val AUC: 0.7371\n",
      "Epoch 28/100, Train Loss: 0.5344, Val Loss: 0.6092, Val Acc: 0.6783, Val AUC: 0.7372\n",
      "Epoch 29/100, Train Loss: 0.5329, Val Loss: 0.6082, Val Acc: 0.6780, Val AUC: 0.7371\n",
      "Epoch 30/100, Train Loss: 0.5332, Val Loss: 0.6104, Val Acc: 0.6767, Val AUC: 0.7375\n",
      "Epoch 31/100, Train Loss: 0.5311, Val Loss: 0.6102, Val Acc: 0.6748, Val AUC: 0.7372\n",
      "Epoch 32/100, Train Loss: 0.5316, Val Loss: 0.6116, Val Acc: 0.6753, Val AUC: 0.7375\n",
      "Epoch 33/100, Train Loss: 0.5316, Val Loss: 0.6086, Val Acc: 0.6757, Val AUC: 0.7369\n",
      "Epoch 34/100, Train Loss: 0.5291, Val Loss: 0.6101, Val Acc: 0.6750, Val AUC: 0.7367\n",
      "Epoch 35/100, Train Loss: 0.5302, Val Loss: 0.6115, Val Acc: 0.6752, Val AUC: 0.7371\n",
      "Epoch 36/100, Train Loss: 0.5312, Val Loss: 0.6078, Val Acc: 0.6752, Val AUC: 0.7371\n",
      "Epoch 37/100, Train Loss: 0.5298, Val Loss: 0.6083, Val Acc: 0.6766, Val AUC: 0.7373\n",
      "Epoch 38/100, Train Loss: 0.5307, Val Loss: 0.6083, Val Acc: 0.6797, Val AUC: 0.7370\n",
      "Epoch 39/100, Train Loss: 0.5322, Val Loss: 0.6088, Val Acc: 0.6773, Val AUC: 0.7364\n",
      "Epoch 40/100, Train Loss: 0.5303, Val Loss: 0.6089, Val Acc: 0.6773, Val AUC: 0.7372\n",
      "Epoch 41/100, Train Loss: 0.5302, Val Loss: 0.6092, Val Acc: 0.6766, Val AUC: 0.7371\n",
      "Epoch 42/100, Train Loss: 0.5323, Val Loss: 0.6105, Val Acc: 0.6750, Val AUC: 0.7364\n",
      "Epoch 43/100, Train Loss: 0.5330, Val Loss: 0.6093, Val Acc: 0.6764, Val AUC: 0.7369\n",
      "Epoch 44/100, Train Loss: 0.5313, Val Loss: 0.6122, Val Acc: 0.6778, Val AUC: 0.7368\n",
      "Epoch 45/100, Train Loss: 0.5297, Val Loss: 0.6099, Val Acc: 0.6745, Val AUC: 0.7373\n",
      "Epoch 46/100, Train Loss: 0.5312, Val Loss: 0.6104, Val Acc: 0.6790, Val AUC: 0.7374\n",
      "Epoch 47/100, Train Loss: 0.5303, Val Loss: 0.6090, Val Acc: 0.6769, Val AUC: 0.7370\n",
      "Epoch 48/100, Train Loss: 0.5315, Val Loss: 0.6076, Val Acc: 0.6776, Val AUC: 0.7373\n",
      "Epoch 49/100, Train Loss: 0.5291, Val Loss: 0.6086, Val Acc: 0.6766, Val AUC: 0.7375\n",
      "Epoch 50/100, Train Loss: 0.5306, Val Loss: 0.6083, Val Acc: 0.6760, Val AUC: 0.7372\n",
      "Epoch 51/100, Train Loss: 0.5337, Val Loss: 0.6087, Val Acc: 0.6785, Val AUC: 0.7372\n",
      "Epoch 52/100, Train Loss: 0.5318, Val Loss: 0.6095, Val Acc: 0.6783, Val AUC: 0.7375\n",
      "Epoch 53/100, Train Loss: 0.5309, Val Loss: 0.6093, Val Acc: 0.6757, Val AUC: 0.7370\n",
      "Epoch 54/100, Train Loss: 0.5321, Val Loss: 0.6096, Val Acc: 0.6774, Val AUC: 0.7371\n",
      "Epoch 55/100, Train Loss: 0.5315, Val Loss: 0.6086, Val Acc: 0.6783, Val AUC: 0.7372\n",
      "Epoch 56/100, Train Loss: 0.5319, Val Loss: 0.6113, Val Acc: 0.6759, Val AUC: 0.7372\n",
      "Epoch 57/100, Train Loss: 0.5329, Val Loss: 0.6114, Val Acc: 0.6792, Val AUC: 0.7368\n",
      "Epoch 58/100, Train Loss: 0.5295, Val Loss: 0.6106, Val Acc: 0.6743, Val AUC: 0.7370\n",
      "Epoch 59/100, Train Loss: 0.5328, Val Loss: 0.6104, Val Acc: 0.6785, Val AUC: 0.7371\n",
      "Epoch 60/100, Train Loss: 0.5322, Val Loss: 0.6073, Val Acc: 0.6767, Val AUC: 0.7371\n",
      "Epoch 61/100, Train Loss: 0.5335, Val Loss: 0.6077, Val Acc: 0.6766, Val AUC: 0.7374\n",
      "Epoch 62/100, Train Loss: 0.5308, Val Loss: 0.6091, Val Acc: 0.6780, Val AUC: 0.7372\n",
      "Epoch 63/100, Train Loss: 0.5319, Val Loss: 0.6115, Val Acc: 0.6781, Val AUC: 0.7372\n",
      "Epoch 64/100, Train Loss: 0.5311, Val Loss: 0.6118, Val Acc: 0.6771, Val AUC: 0.7370\n",
      "Epoch 65/100, Train Loss: 0.5318, Val Loss: 0.6112, Val Acc: 0.6764, Val AUC: 0.7368\n",
      "Epoch 66/100, Train Loss: 0.5317, Val Loss: 0.6131, Val Acc: 0.6774, Val AUC: 0.7371\n",
      "Epoch 67/100, Train Loss: 0.5327, Val Loss: 0.6076, Val Acc: 0.6766, Val AUC: 0.7371\n",
      "Epoch 68/100, Train Loss: 0.5323, Val Loss: 0.6087, Val Acc: 0.6774, Val AUC: 0.7379\n",
      "Epoch 69/100, Train Loss: 0.5327, Val Loss: 0.6083, Val Acc: 0.6759, Val AUC: 0.7373\n",
      "Epoch 70/100, Train Loss: 0.5304, Val Loss: 0.6083, Val Acc: 0.6748, Val AUC: 0.7369\n",
      "Epoch 71/100, Train Loss: 0.5328, Val Loss: 0.6099, Val Acc: 0.6752, Val AUC: 0.7370\n",
      "Epoch 72/100, Train Loss: 0.5305, Val Loss: 0.6073, Val Acc: 0.6780, Val AUC: 0.7372\n",
      "Epoch 73/100, Train Loss: 0.5327, Val Loss: 0.6094, Val Acc: 0.6771, Val AUC: 0.7378\n",
      "Epoch 74/100, Train Loss: 0.5310, Val Loss: 0.6066, Val Acc: 0.6771, Val AUC: 0.7373\n",
      "Epoch 75/100, Train Loss: 0.5311, Val Loss: 0.6086, Val Acc: 0.6760, Val AUC: 0.7371\n",
      "Epoch 76/100, Train Loss: 0.5329, Val Loss: 0.6093, Val Acc: 0.6774, Val AUC: 0.7367\n",
      "Epoch 77/100, Train Loss: 0.5306, Val Loss: 0.6081, Val Acc: 0.6748, Val AUC: 0.7368\n",
      "Epoch 78/100, Train Loss: 0.5306, Val Loss: 0.6105, Val Acc: 0.6774, Val AUC: 0.7366\n",
      "Epoch 79/100, Train Loss: 0.5305, Val Loss: 0.6136, Val Acc: 0.6733, Val AUC: 0.7374\n",
      "Epoch 80/100, Train Loss: 0.5327, Val Loss: 0.6104, Val Acc: 0.6760, Val AUC: 0.7364\n",
      "Epoch 81/100, Train Loss: 0.5326, Val Loss: 0.6104, Val Acc: 0.6757, Val AUC: 0.7371\n",
      "Epoch 82/100, Train Loss: 0.5324, Val Loss: 0.6106, Val Acc: 0.6766, Val AUC: 0.7368\n",
      "Epoch 83/100, Train Loss: 0.5317, Val Loss: 0.6088, Val Acc: 0.6760, Val AUC: 0.7375\n",
      "Epoch 84/100, Train Loss: 0.5337, Val Loss: 0.6097, Val Acc: 0.6764, Val AUC: 0.7372\n",
      "Epoch 85/100, Train Loss: 0.5328, Val Loss: 0.6066, Val Acc: 0.6769, Val AUC: 0.7370\n",
      "Epoch 86/100, Train Loss: 0.5307, Val Loss: 0.6087, Val Acc: 0.6774, Val AUC: 0.7369\n",
      "Epoch 87/100, Train Loss: 0.5330, Val Loss: 0.6104, Val Acc: 0.6760, Val AUC: 0.7375\n",
      "Epoch 88/100, Train Loss: 0.5343, Val Loss: 0.6076, Val Acc: 0.6778, Val AUC: 0.7370\n",
      "Epoch 89/100, Train Loss: 0.5307, Val Loss: 0.6097, Val Acc: 0.6759, Val AUC: 0.7367\n",
      "Epoch 90/100, Train Loss: 0.5283, Val Loss: 0.6116, Val Acc: 0.6774, Val AUC: 0.7368\n",
      "Epoch 91/100, Train Loss: 0.5329, Val Loss: 0.6085, Val Acc: 0.6774, Val AUC: 0.7378\n",
      "Epoch 92/100, Train Loss: 0.5291, Val Loss: 0.6105, Val Acc: 0.6762, Val AUC: 0.7368\n",
      "Epoch 93/100, Train Loss: 0.5310, Val Loss: 0.6110, Val Acc: 0.6736, Val AUC: 0.7369\n",
      "Epoch 94/100, Train Loss: 0.5314, Val Loss: 0.6108, Val Acc: 0.6769, Val AUC: 0.7367\n",
      "Epoch 95/100, Train Loss: 0.5274, Val Loss: 0.6092, Val Acc: 0.6781, Val AUC: 0.7370\n",
      "Epoch 96/100, Train Loss: 0.5328, Val Loss: 0.6075, Val Acc: 0.6774, Val AUC: 0.7374\n",
      "Epoch 97/100, Train Loss: 0.5302, Val Loss: 0.6080, Val Acc: 0.6771, Val AUC: 0.7376\n",
      "Epoch 98/100, Train Loss: 0.5324, Val Loss: 0.6085, Val Acc: 0.6773, Val AUC: 0.7373\n",
      "Epoch 99/100, Train Loss: 0.5322, Val Loss: 0.6089, Val Acc: 0.6757, Val AUC: 0.7369\n",
      "Epoch 100/100, Train Loss: 0.5309, Val Loss: 0.6079, Val Acc: 0.6750, Val AUC: 0.7370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [0.6163133018960555,\n",
       "  0.5976323392656114,\n",
       "  0.5911967740704616,\n",
       "  0.5898128296352095,\n",
       "  0.5853117661343681,\n",
       "  0.5817532922244735,\n",
       "  0.5776746368656556,\n",
       "  0.5759394769039419,\n",
       "  0.5690029778828224,\n",
       "  0.5645119466715389,\n",
       "  0.5521917016969786,\n",
       "  0.5487025638421377,\n",
       "  0.5467156305909157,\n",
       "  0.5414758675628238,\n",
       "  0.5416504581355386,\n",
       "  0.540240859405862,\n",
       "  0.5378663677308294,\n",
       "  0.5355301716675361,\n",
       "  0.5350934070431523,\n",
       "  0.5357806621326341,\n",
       "  0.5335787710630231,\n",
       "  0.5345678663088216,\n",
       "  0.5305696334275934,\n",
       "  0.5308158396846718,\n",
       "  0.5340645468069447,\n",
       "  0.5306105573972066,\n",
       "  0.5324103205154339,\n",
       "  0.5343653436750173,\n",
       "  0.5328534767859512,\n",
       "  0.5331697201563252,\n",
       "  0.5311056833714247,\n",
       "  0.5315784826460812,\n",
       "  0.531610753097468,\n",
       "  0.5290778868314293,\n",
       "  0.5301838826388121,\n",
       "  0.5312238537602955,\n",
       "  0.5297626044601202,\n",
       "  0.5306709908362892,\n",
       "  0.5321547002014186,\n",
       "  0.5302957510782613,\n",
       "  0.5301965557038784,\n",
       "  0.5322521960155832,\n",
       "  0.5330247537543377,\n",
       "  0.5312880797932545,\n",
       "  0.5297436240232654,\n",
       "  0.5311780716809962,\n",
       "  0.5302626281562779,\n",
       "  0.531468019882838,\n",
       "  0.529113174850742,\n",
       "  0.5306088775810268,\n",
       "  0.5336771487775777,\n",
       "  0.5317889355950886,\n",
       "  0.530924444935388,\n",
       "  0.5320850956357188,\n",
       "  0.5315118023090892,\n",
       "  0.5319275583244032,\n",
       "  0.5328581429604027,\n",
       "  0.5294627620114221,\n",
       "  0.5327820490631793,\n",
       "  0.5321801736536953,\n",
       "  0.5334748664249976,\n",
       "  0.5307626398901145,\n",
       "  0.5319254413247109,\n",
       "  0.5310819165160259,\n",
       "  0.5317738643536966,\n",
       "  0.5316561809844441,\n",
       "  0.5326875361717409,\n",
       "  0.5322529855701659,\n",
       "  0.5327447784443696,\n",
       "  0.5304189701047208,\n",
       "  0.5327703772733609,\n",
       "  0.530451347761684,\n",
       "  0.5326507716543145,\n",
       "  0.5310436214837763,\n",
       "  0.5311431471672323,\n",
       "  0.5328715005268653,\n",
       "  0.5305833666688866,\n",
       "  0.5306266271819671,\n",
       "  0.5305031771461169,\n",
       "  0.5327040643741687,\n",
       "  0.5325549229565594,\n",
       "  0.5324250781287749,\n",
       "  0.531690354562468,\n",
       "  0.5337380488713582,\n",
       "  0.5327528704785638,\n",
       "  0.5306818671110604,\n",
       "  0.5330283233275016,\n",
       "  0.5343235093272395,\n",
       "  0.5306753541446394,\n",
       "  0.5283279588652982,\n",
       "  0.5328621364302105,\n",
       "  0.5291395598815547,\n",
       "  0.5309769986404314,\n",
       "  0.5313826221558783,\n",
       "  0.5273869866712226,\n",
       "  0.5327558100637463,\n",
       "  0.5302198271370596,\n",
       "  0.5323505975306034,\n",
       "  0.5321714582956499,\n",
       "  0.5309260362552272],\n",
       " 'val_loss': [0.5935727419124709,\n",
       "  0.592480872074763,\n",
       "  0.5950093309084574,\n",
       "  0.5916516082154379,\n",
       "  0.5929949371351136,\n",
       "  0.5922801792621613,\n",
       "  0.5952468540933397,\n",
       "  0.599381141199006,\n",
       "  0.5950827590293355,\n",
       "  0.5988826402359538,\n",
       "  0.5983643884460131,\n",
       "  0.5999839991331101,\n",
       "  0.6003838153349028,\n",
       "  0.6016231036848492,\n",
       "  0.6040531352162362,\n",
       "  0.6026910841464996,\n",
       "  0.6051568607489268,\n",
       "  0.6051284059882164,\n",
       "  0.6078583712379138,\n",
       "  0.6102703771657414,\n",
       "  0.6077784975369771,\n",
       "  0.6071481900082694,\n",
       "  0.6092761854330698,\n",
       "  0.6113578980167707,\n",
       "  0.6100673331154718,\n",
       "  0.6103706013825204,\n",
       "  0.6101915013458994,\n",
       "  0.6092398777604103,\n",
       "  0.608203064236376,\n",
       "  0.6103901012076272,\n",
       "  0.6102226421236991,\n",
       "  0.6115576556987232,\n",
       "  0.6086173618833224,\n",
       "  0.610141191052066,\n",
       "  0.6114965266651577,\n",
       "  0.6077637813157506,\n",
       "  0.6083233669400215,\n",
       "  0.6083486085136731,\n",
       "  0.6088430240750313,\n",
       "  0.6088839029272397,\n",
       "  0.6092118635773659,\n",
       "  0.6105168357491493,\n",
       "  0.6093471257223023,\n",
       "  0.6121610167953703,\n",
       "  0.6098963591787551,\n",
       "  0.6103508002228207,\n",
       "  0.6089536534415351,\n",
       "  0.6075958823164304,\n",
       "  0.6085652995440695,\n",
       "  0.6082516468233532,\n",
       "  0.6086780213647418,\n",
       "  0.6095375176933077,\n",
       "  0.6092636961075995,\n",
       "  0.6096485510468483,\n",
       "  0.6085925633708636,\n",
       "  0.6112587821152475,\n",
       "  0.6114362383882205,\n",
       "  0.6105972232090102,\n",
       "  0.6103534145487679,\n",
       "  0.6073362583915393,\n",
       "  0.6076750910944408,\n",
       "  0.6090502858161926,\n",
       "  0.6114997077319357,\n",
       "  0.6117644114626779,\n",
       "  0.6111770715978411,\n",
       "  0.6130846175882552,\n",
       "  0.6076392816172705,\n",
       "  0.6086789809995228,\n",
       "  0.608332980175813,\n",
       "  0.6083250015974044,\n",
       "  0.6099388808012008,\n",
       "  0.6072844369543924,\n",
       "  0.6093640618854099,\n",
       "  0.6066378053691652,\n",
       "  0.6085922153459655,\n",
       "  0.6092951052718693,\n",
       "  0.608147521979279,\n",
       "  0.610502461095651,\n",
       "  0.6136224249998729,\n",
       "  0.6104112376769384,\n",
       "  0.6104414915045102,\n",
       "  0.6106206501523653,\n",
       "  0.608822581006421,\n",
       "  0.6097418308258057,\n",
       "  0.6065585795376036,\n",
       "  0.6086953135000335,\n",
       "  0.6104243089755376,\n",
       "  0.607567703558339,\n",
       "  0.6096880152821541,\n",
       "  0.6115503008166949,\n",
       "  0.6085169264011913,\n",
       "  0.6104515512784322,\n",
       "  0.6109831192427211,\n",
       "  0.6107834385501014,\n",
       "  0.6092459294531081,\n",
       "  0.6075234828723801,\n",
       "  0.6080472924643092,\n",
       "  0.6085495301418834,\n",
       "  0.6089004543092515,\n",
       "  0.6078789931204583],\n",
       " 'val_accuracy': [0.6828125,\n",
       "  0.6802083333333333,\n",
       "  0.6803819444444444,\n",
       "  0.6833333333333333,\n",
       "  0.6835069444444445,\n",
       "  0.6798611111111111,\n",
       "  0.6786458333333333,\n",
       "  0.6791666666666667,\n",
       "  0.6822916666666666,\n",
       "  0.6774305555555555,\n",
       "  0.6777777777777778,\n",
       "  0.6779513888888888,\n",
       "  0.6777777777777778,\n",
       "  0.6776041666666667,\n",
       "  0.6777777777777778,\n",
       "  0.6805555555555556,\n",
       "  0.6762152777777778,\n",
       "  0.6774305555555555,\n",
       "  0.6774305555555555,\n",
       "  0.6779513888888888,\n",
       "  0.6772569444444444,\n",
       "  0.6777777777777778,\n",
       "  0.6737847222222222,\n",
       "  0.6730902777777777,\n",
       "  0.6737847222222222,\n",
       "  0.6782986111111111,\n",
       "  0.6760416666666667,\n",
       "  0.6782986111111111,\n",
       "  0.6779513888888888,\n",
       "  0.6767361111111111,\n",
       "  0.6748263888888889,\n",
       "  0.6753472222222222,\n",
       "  0.6756944444444445,\n",
       "  0.675,\n",
       "  0.6751736111111111,\n",
       "  0.6751736111111111,\n",
       "  0.6765625,\n",
       "  0.6796875,\n",
       "  0.6772569444444444,\n",
       "  0.6772569444444444,\n",
       "  0.6765625,\n",
       "  0.675,\n",
       "  0.6763888888888889,\n",
       "  0.6777777777777778,\n",
       "  0.6744791666666666,\n",
       "  0.6789930555555556,\n",
       "  0.6769097222222222,\n",
       "  0.6776041666666667,\n",
       "  0.6765625,\n",
       "  0.6760416666666667,\n",
       "  0.6784722222222223,\n",
       "  0.6782986111111111,\n",
       "  0.6756944444444445,\n",
       "  0.6774305555555555,\n",
       "  0.6782986111111111,\n",
       "  0.6758680555555555,\n",
       "  0.6791666666666667,\n",
       "  0.6743055555555556,\n",
       "  0.6784722222222223,\n",
       "  0.6767361111111111,\n",
       "  0.6765625,\n",
       "  0.6779513888888888,\n",
       "  0.678125,\n",
       "  0.6770833333333334,\n",
       "  0.6763888888888889,\n",
       "  0.6774305555555555,\n",
       "  0.6765625,\n",
       "  0.6774305555555555,\n",
       "  0.6758680555555555,\n",
       "  0.6748263888888889,\n",
       "  0.6751736111111111,\n",
       "  0.6779513888888888,\n",
       "  0.6770833333333334,\n",
       "  0.6770833333333334,\n",
       "  0.6760416666666667,\n",
       "  0.6774305555555555,\n",
       "  0.6748263888888889,\n",
       "  0.6774305555555555,\n",
       "  0.6732638888888889,\n",
       "  0.6760416666666667,\n",
       "  0.6756944444444445,\n",
       "  0.6765625,\n",
       "  0.6760416666666667,\n",
       "  0.6763888888888889,\n",
       "  0.6769097222222222,\n",
       "  0.6774305555555555,\n",
       "  0.6760416666666667,\n",
       "  0.6777777777777778,\n",
       "  0.6758680555555555,\n",
       "  0.6774305555555555,\n",
       "  0.6774305555555555,\n",
       "  0.6762152777777778,\n",
       "  0.6736111111111112,\n",
       "  0.6769097222222222,\n",
       "  0.678125,\n",
       "  0.6774305555555555,\n",
       "  0.6770833333333334,\n",
       "  0.6772569444444444,\n",
       "  0.6756944444444445,\n",
       "  0.675],\n",
       " 'val_auc': [0.7457249275067042,\n",
       "  0.7480884166863402,\n",
       "  0.743629862477441,\n",
       "  0.7478592386662566,\n",
       "  0.7461091519674364,\n",
       "  0.7472202171837243,\n",
       "  0.7451384158929385,\n",
       "  0.7438285762945379,\n",
       "  0.7445025437912318,\n",
       "  0.7413039841726654,\n",
       "  0.7421830853781395,\n",
       "  0.7423847668810143,\n",
       "  0.7415077854510961,\n",
       "  0.741456547447663,\n",
       "  0.7407411534801082,\n",
       "  0.740591436760857,\n",
       "  0.7400215199614418,\n",
       "  0.7383895956086003,\n",
       "  0.7380329887951087,\n",
       "  0.7371927703298287,\n",
       "  0.7371603680463337,\n",
       "  0.7372799839526933,\n",
       "  0.7367720251645218,\n",
       "  0.7373215315535859,\n",
       "  0.7368401002423691,\n",
       "  0.7375556759049716,\n",
       "  0.7371185781853776,\n",
       "  0.7371503748187138,\n",
       "  0.7371031341063288,\n",
       "  0.7375353260596362,\n",
       "  0.737188591343733,\n",
       "  0.7374695524523927,\n",
       "  0.7368721391357687,\n",
       "  0.7367332029893439,\n",
       "  0.737134325089506,\n",
       "  0.737126391072426,\n",
       "  0.7372591495872314,\n",
       "  0.7369790969538099,\n",
       "  0.7363733862300107,\n",
       "  0.7372449773735158,\n",
       "  0.7371448028372529,\n",
       "  0.7364476995044933,\n",
       "  0.7368834042287221,\n",
       "  0.7367757196304905,\n",
       "  0.7372610271027235,\n",
       "  0.7374182538839436,\n",
       "  0.7370131344927335,\n",
       "  0.7372780458721853,\n",
       "  0.7375126141786821,\n",
       "  0.7372093651441793,\n",
       "  0.7371606708714131,\n",
       "  0.7374826344958223,\n",
       "  0.7370489889821333,\n",
       "  0.7370997424654395,\n",
       "  0.7372272923888793,\n",
       "  0.737173147264684,\n",
       "  0.7368121192050332,\n",
       "  0.7370091372016856,\n",
       "  0.7370819363507712,\n",
       "  0.7371317207938232,\n",
       "  0.7373928165772747,\n",
       "  0.7372362560112291,\n",
       "  0.737223416227863,\n",
       "  0.7369509947864423,\n",
       "  0.7368442792284646,\n",
       "  0.7371349307396649,\n",
       "  0.7370786658399139,\n",
       "  0.737879517044873,\n",
       "  0.7372824671183444,\n",
       "  0.7368971524873266,\n",
       "  0.7369953283780653,\n",
       "  0.7372361348811975,\n",
       "  0.7378178012936929,\n",
       "  0.7373311008260948,\n",
       "  0.737115368239536,\n",
       "  0.7366710027180368,\n",
       "  0.7368486399096079,\n",
       "  0.736557927833392,\n",
       "  0.7373730723820985,\n",
       "  0.7364054251234102,\n",
       "  0.7371117949035992,\n",
       "  0.7368115741198904,\n",
       "  0.7375228496663656,\n",
       "  0.7371775079458273,\n",
       "  0.7370454762112125,\n",
       "  0.7368551809313227,\n",
       "  0.7374914769881404,\n",
       "  0.736987515491017,\n",
       "  0.736736110110106,\n",
       "  0.7367864396383008,\n",
       "  0.7377540263319731,\n",
       "  0.7368113318598268,\n",
       "  0.7368508202501796,\n",
       "  0.7366908680432449,\n",
       "  0.73702082624975,\n",
       "  0.7374190412291499,\n",
       "  0.7376134549301194,\n",
       "  0.7373013634032984,\n",
       "  0.7368584514421802,\n",
       "  0.7370178585639721]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model, loss, and optimizer\n",
    "model = ImprovedNet(input_dim=X_train.shape[1])\n",
    "criterion = nn.BCELoss() # Binary cross-entropy loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "training(model, criterion, optimizer, 100, train_loader, val_loader, 'mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8487c5-0b94-47ee-b8b8-abc22bdbbdfc",
   "metadata": {},
   "source": [
    "# Non traditional method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c19a1d-3f2c-4d3b-9a33-8539b87bf1b3",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ddd952f-0314-4eb4-b2fe-5410c140d4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.69296\teval-auc:0.66999\n",
      "[10]\ttrain-auc:0.75606\teval-auc:0.72814\n",
      "[20]\ttrain-auc:0.77368\teval-auc:0.73655\n",
      "[30]\ttrain-auc:0.78955\teval-auc:0.74152\n",
      "[40]\ttrain-auc:0.80433\teval-auc:0.74609\n",
      "[50]\ttrain-auc:0.81473\teval-auc:0.74908\n",
      "[60]\ttrain-auc:0.82327\teval-auc:0.75004\n",
      "[68]\ttrain-auc:0.83090\teval-auc:0.74995\n",
      "Validation AUC: 0.7500\n",
      "Validation ACC: 0.6839\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "train_data = pd.read_csv('Data/train.csv')\n",
    "\n",
    "# Handle missing values \n",
    "train_data = handle_missing_values(train_data)\n",
    "\n",
    "# Separate target and features\n",
    "y = train_data['efs']\n",
    "X = train_data.drop(columns=['efs', 'efs_time', 'ID'], errors='ignore')\n",
    "\n",
    "# Encode categorical variables\n",
    "cat_cols = [col for col in X.columns if X[col].dtype=='object']\n",
    "X = pd.get_dummies(X, columns=cat_cols, dummy_na=False)\n",
    "\n",
    "# Scale numeric features\n",
    "num_cols = [col for col in X.columns if X[col].dtype != 'uint8']\n",
    "scaler = StandardScaler()\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_array = X.values\n",
    "y_array = y.values\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_array, y_array, test_size = 0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to DMatrix for XGBoost\n",
    "train_dmatrix = xgb.DMatrix(X_train, label=y_train)\n",
    "val_dmatrix = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Define XGBoost paramters\n",
    "params = {\n",
    "    \"objective\" : \"binary:logistic\", # Binary classification\n",
    "    \"eval_metric\" : \"auc\",           # Evaluation metric\n",
    "    \"eta\" : 0.1,                     # Learning rate\n",
    "    \"max_depth\" : 6,                 # Max depth of tress\n",
    "    \"subsample\" : 0.8,               # Row sampling\n",
    "    \"colsample_bytree\" : 0.8,        # Feature Sampling\n",
    "    \"lambda\" : 1,                    # L2 regularization\n",
    "    \"alpha\" : 0                      # L1 regularization\n",
    "}\n",
    "\n",
    "# Trian the model\n",
    "evals = [(train_dmatrix, 'train'), (val_dmatrix, 'eval')]\n",
    "num_boost_round = 200\n",
    "early_stopping_rounds = 10\n",
    "\n",
    "xgb_model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=train_dmatrix,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=early_stopping_rounds,\n",
    "    verbose_eval=10\n",
    ")\n",
    "\n",
    "# Make predictions on validation set\n",
    "val_preds = xgb_model.predict(val_dmatrix)\n",
    "val_preds_binary = (val_preds >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate model\n",
    "auc = roc_auc_score(y_val, val_preds)\n",
    "acc = accuracy_score(y_val, val_preds_binary)\n",
    "\n",
    "print(f\"Validation AUC: {auc:.4f}\")\n",
    "print(f\"Validation ACC: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8452b6-2a0a-4956-9963-b05f9b837a51",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7448c3d-e0b2-451f-817f-13b1951a567c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's auc: 0.742947\teval's auc: 0.726273\n",
      "[20]\ttrain's auc: 0.759245\teval's auc: 0.735371\n",
      "[30]\ttrain's auc: 0.774242\teval's auc: 0.741467\n",
      "[40]\ttrain's auc: 0.785755\teval's auc: 0.746016\n",
      "[50]\ttrain's auc: 0.797085\teval's auc: 0.748616\n",
      "[60]\ttrain's auc: 0.805966\teval's auc: 0.750482\n",
      "[70]\ttrain's auc: 0.813671\teval's auc: 0.752309\n",
      "[80]\ttrain's auc: 0.820852\teval's auc: 0.753117\n",
      "[90]\ttrain's auc: 0.828277\teval's auc: 0.75346\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttrain's auc: 0.826883\teval's auc: 0.753681\n",
      "Validation AUC: 0.7537\n",
      "Validation Accuracy: 0.6891\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "# load the data\n",
    "train_data = pd.read_csv('Data/train.csv')\n",
    "\n",
    "# Handle missing values\n",
    "train_data = handle_missing_values(train_data)\n",
    "\n",
    "# Separate target and features\n",
    "y = train_data['efs']\n",
    "X = train_data.drop(columns=['efs', 'efs_time', 'ID'], errors='ignore')\n",
    "\n",
    "# Encode categorical variables\n",
    "cat_cols = [col for col in X.columns if X[col].dtype=='object']\n",
    "X = pd.get_dummies(X, columns=cat_cols, dummy_na=False)\n",
    "\n",
    "# Scale numeric features\n",
    "num_cols = [col for col in X.columns if X[col].dtype!='uint8']\n",
    "scaler = StandardScaler()\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_array = X.values\n",
    "y_array = y.values\n",
    "\n",
    "# Split into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_array, y_array, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert categorical column indices \n",
    "categorical_features = [X.columns.get_loc(col) for col in cat_cols if col in X.columns]\n",
    "\n",
    "# LightGBM dataset\n",
    "train_dataset = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features)\n",
    "val_dataset = lgb.Dataset(X_val, label=y_val, categorical_feature=categorical_features, reference=train_dataset)\n",
    "\n",
    "# Define LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc', # Evaluation metric\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31, # Controls complexity of the tree,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.8, # Randomly select a fraction of features for each iteration\n",
    "    'bagging_fraction': 0.8, # Randomly select a fraction of data for each iteration\n",
    "    'bagging_freq': 5, # Frequency of bagging\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "num_round = 200\n",
    "early_stopping_rounds = 10\n",
    "lgb_model = lgb.train(\n",
    "    params=params,\n",
    "    train_set=train_dataset,\n",
    "    num_boost_round=num_round,\n",
    "    valid_sets=[train_dataset, val_dataset],\n",
    "    valid_names=['train', 'eval'],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=early_stopping_rounds),\n",
    "        lgb.log_evaluation(10)\n",
    "    ]\n",
    ")\n",
    "# Make predictions on validation set\n",
    "val_preds = lgb_model.predict(X_val, num_iteration=lgb_model.best_iteration)\n",
    "val_preds_binary = (val_preds >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate model\n",
    "auc = roc_auc_score(y_val, val_preds)\n",
    "accuracy = accuracy_score(y_val, val_preds_binary)\n",
    "\n",
    "print(f\"Validation AUC: {auc:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a51b36-e276-48a3-83ad-fa18200ebf91",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3177abf-787a-4e6c-b857-7ed20096ca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.7297\n",
      "Validation Accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv('Data/train.csv')\n",
    "\n",
    "# Hanlde missing values\n",
    "train_data = handle_missing_values(train_data)\n",
    "\n",
    "# Separate target and features \n",
    "y = train_data['efs']\n",
    "X = train_data.drop(columns=['efs', 'efs_time', 'ID'], errors='ignore')\n",
    "\n",
    "# Encode categorical variables\n",
    "cat_cols = [col for col in X.columns if X[col].dtype=='object']\n",
    "X = pd.get_dummies(X, columns=cat_cols, dummy_na=False)\n",
    "\n",
    "# Scale numeric ceatures\n",
    "num_cols = [col for col in X.columns if col not in cat_cols]\n",
    "scaler = StandardScaler()\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_array = X.values\n",
    "y_array = y.values\n",
    "\n",
    "# Split into train and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_array, y_array, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,         # Number of trees in the forest\n",
    "    max_depth=10,            # Maximum depth of the tree\n",
    "    min_samples_split=5,     # Maximum samples to split a node\n",
    "    min_samples_leaf=2,      # Minimum samples at leaf node\n",
    "    max_features='sqrt',     # Number of features to consider at each split\n",
    "    random_state=42,         # For reproducibility\n",
    "    n_jobs=-1,               # Use all available cores for training\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on validation set\n",
    "val_preds = rf_model.predict_proba(X_val)[:,1] # Probability of positive class\n",
    "val_preds_binary = (val_preds >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "auc = roc_auc_score(y_val, val_preds)\n",
    "accuracy = accuracy_score(y_val, val_preds_binary)\n",
    "\n",
    "print(f\"Validation AUC: {auc:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20f805-b543-48e0-9eba-e9155c53cb0b",
   "metadata": {},
   "source": [
    "## Simple Ensemble (RandomForestClassifier, XGBClassifier, LGBMClassifier)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd727c9-5256-48d5-9b4a-139c5e3da073",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dabaebb-377b-4192-a0d8-2299042fa1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joowanlim/Desktop/CIBMTR/env/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [06:54:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.7531\n",
      "Validation Accuracy: 0.6875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Initialize individual models\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=200, \n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    ")\n",
    "\n",
    "lgbm_model = LGBMClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combine models in voting classifier\n",
    "voting_ensemble = VotingClassifier(\n",
    "    estimators=[('rf', rf_model), ('xgb', xgb_model),('lgbm', lgbm_model)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Train ensemble model\n",
    "voting_ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "val_preds = voting_ensemble.predict_proba(X_val)[:,1]\n",
    "val_preds_binary = (val_preds >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate model\n",
    "auc = roc_auc_score(y_val, val_preds)\n",
    "accuracy = accuracy_score(y_val, val_preds_binary)\n",
    "\n",
    "print(f\"Validation AUC: {auc:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f9fdea-eba9-4491-9905-59041f6df114",
   "metadata": {},
   "source": [
    "## Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fcd24df-9f7d-4385-b5aa-675eb86e49e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joowanlim/Desktop/CIBMTR/env/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [06:54:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/joowanlim/Desktop/CIBMTR/env/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [06:54:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/joowanlim/Desktop/CIBMTR/env/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [06:54:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.7532\n",
      "Validation Accuracy: 0.6875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize base models\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100,\n",
    "                                  max_depth=10,\n",
    "                                  random_state=42,\n",
    "                                  n_jobs=-1)),\n",
    "    ('xgb', XGBClassifier(n_estimators=200,\n",
    "                          max_depth=6,\n",
    "                          learning_rate=0.1,\n",
    "                          random_state=42,\n",
    "                          use_label_encoder=False,\n",
    "                          eval_metric='logloss'\n",
    "                          )),\n",
    "    ('lgbm', LGBMClassifier(n_estimators=200,\n",
    "                            learning_rate=0.1,\n",
    "                            num_leaves=31,\n",
    "                            random_state=42))\n",
    "]\n",
    "\n",
    "# Meta-modeling \n",
    "meta_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Create stacking ensemble\n",
    "stacking_ensemble = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5 # Use cross-validation\n",
    ")\n",
    "\n",
    "# Train stacking ensemble\n",
    "stacking_ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "val_preds = stacking_ensemble.predict_proba(X_val)[:,1]\n",
    "val_preds_binary = (val_preds >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate model\n",
    "auc = roc_auc_score(y_val, val_preds)\n",
    "accuracy_score = accuracy_score(y_val, val_preds_binary)\n",
    "\n",
    "print(f\"Validation AUC: {auc:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550d9130-fcb0-44e3-accc-424f3412d838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c6a50-cd0c-4ad7-af54-ceccd92f95d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bf5492-b7cf-4235-a209-fa0219cc01f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7180dc20-ff73-43d4-8eeb-6efc95b5a0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f608a07-cbc4-43b3-9efd-d4c12849b4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3445c-31ef-418f-9f62-45292c41c90d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9dbcfc-0016-403c-a8ba-c77a48e426a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIBMTR_venv",
   "language": "python",
   "name": "cibmtr_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
